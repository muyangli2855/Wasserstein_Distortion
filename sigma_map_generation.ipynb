{"cells":[{"cell_type":"code","execution_count":null,"id":"8ec44693-d164-4eaa-9828-c888abfe52ff","metadata":{"id":"8ec44693-d164-4eaa-9828-c888abfe52ff","outputId":"ef11bb87-8b6b-43a3-d59b-c065cec18c99"},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-05-01 15:43:41.190403: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-05-01 15:43:42.853100: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/chiu/.local/lib/python3.10/site_packages/tensorrt:/usr/local/cuda-12.4/targets/x86_64-linux/lib:/usr/local/cuda-12.4/lib64:/usr/local/cuda-12.0/targets/x86_64-linux/lib:\n","2024-05-01 15:43:42.853179: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/chiu/.local/lib/python3.10/site_packages/tensorrt:/usr/local/cuda-12.4/targets/x86_64-linux/lib:/usr/local/cuda-12.4/lib64:/usr/local/cuda-12.0/targets/x86_64-linux/lib:\n","2024-05-01 15:43:42.853184: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"]}],"source":["import numpy as np\n","import keras.utils as image\n","from PIL import Image\n","import skimage.measure\n","import math\n","import sys\n","import os\n","import time\n","\n","from keras import backend as K\n","import tensorflow as tf"]},{"cell_type":"code","execution_count":null,"id":"e1a76ff6-d0cd-462f-ad2a-c1cd30f18535","metadata":{"id":"e1a76ff6-d0cd-462f-ad2a-c1cd30f18535"},"outputs":[],"source":["filename = 'sheepdog'\n","img = image.load_img('./SALICON/'+filename+'.jpg')\n","height,width = img.size\n","channels = 3\n","img = image.img_to_array(img)\n","img = img[:, :, ::-1]\n","img = np.expand_dims(img, axis=0)\n","tex_pixels = tf.squeeze(img)/255."]},{"cell_type":"code","execution_count":null,"id":"ebc58307-247b-4400-af90-55308961c609","metadata":{"id":"ebc58307-247b-4400-af90-55308961c609"},"outputs":[],"source":["threshold=0.1\n","max_sigma = 235\n","sigma_sequence = [1.0, 1.5, 2.0, 4.0, 7.0, 10.0]\n","increment = 5.0\n","increment_steps = [5.0, 10.0, 20.0, 40.0, 50.0]\n","increment_index = 0\n","step_counter = 0\n","current_sigma = sigma_sequence[-1] + increment\n","while current_sigma <= max_sigma:\n","    sigma_sequence.append(current_sigma)\n","    step_counter += 1\n","    if step_counter % 5 == 0 and increment_index < len(increment_steps) - 1:\n","        increment_index += 1\n","        increment = increment_steps[increment_index]\n","    current_sigma += increment\n","    if current_sigma >= max_sigma:\n","        sigma_sequence.append(max_sigma)\n","        break"]},{"cell_type":"code","execution_count":null,"id":"f4587499-a824-4e14-8c3b-60cba1258ffe","metadata":{"id":"f4587499-a824-4e14-8c3b-60cba1258ffe"},"outputs":[],"source":["tsg_lists = {}\n","for sigma in sigma_sequence:\n","    kernel_size = int(4 * sigma - 1)\n","    current_height = int(kernel_size / 2)\n","    current_width = int(kernel_size / 2)\n","    tsg_current = np.array([[np.exp(-((i_ref_p)**2 + (j_ref_p)**2) / (2*sigma**2)) \\\n","                          for j_ref_p in range(-current_width, current_width + 1)] \\\n","                         for i_ref_p in range(-current_height, current_height + 1)])\n","\n","    tsg_current = tsg_current / np.sum(tsg_current)\n","    tsg_current = np.expand_dims(tsg_current, axis=-1)  # Add a third dimension for 'in_channels'\n","    tsg_current = np.expand_dims(tsg_current, axis=-1)  # Add a fourth dimension for 'out_channels'\n","    tsg_current = np.repeat(tsg_current, 3, axis=-1)\n","    tsg_current_tf = tf.convert_to_tensor(tsg_current, dtype=tf.float32)\n","    tsg_lists[sigma] = tsg_current_tf"]},{"cell_type":"code","execution_count":null,"id":"c76b9c17-2419-4314-8594-6938cd1832d1","metadata":{"id":"c76b9c17-2419-4314-8594-6938cd1832d1"},"outputs":[],"source":["mean_tex_all = []\n","var_tex_all = []\n","for sigma in sigma_sequence:\n","    tsg = tsg_lists[sigma]\n","    tex = tf.expand_dims(tex_pixels, axis=0)  # Add batch dimension\n","    kernel_size = len(tsg)\n","    padding_size = int((kernel_size + 1) / 2) - 1\n","    padding = tf.constant([[0, 0], [padding_size, padding_size], [padding_size, padding_size], [0, 0]])\n","    tex_padded = tf.pad(tex, padding, \"SYMMETRIC\")\n","    # Convolution\n","    mean_tex = tf.nn.conv2d(tex_padded, tsg, strides=[1, 1, 1, 1], padding='VALID')\n","    mean_tex_padded = tf.pad(mean_tex, padding, \"SYMMETRIC\")\n","    squared_diff_tex = (tex_padded - mean_tex_padded) ** 2\n","    var_tex = tf.maximum(tf.nn.conv2d(squared_diff_tex, tsg, strides=[1, 1, 1, 1], padding='VALID'), 0)\n","    mean_tex_all.append(mean_tex)\n","    var_tex_all.append(var_tex)\n","\n","mean_tex_all = np.concatenate(mean_tex_all,axis=0)\n","var_tex_all = np.concatenate(var_tex_all,axis=0)\n","wd_sigma_list = (mean_tex_all[1:,:,:,:] - mean_tex_all[:-1,:,:,:])**2 + var_tex_all[1:,:,:,:] + var_tex_all[:-1,:,:,:] -\\\n","                                            2*tf.math.sqrt(var_tex_all[1:,:,:,:]*var_tex_all[:-1,:,:,:])\n","wd_sigma_list = tf.math.reduce_mean(wd_sigma_list,axis=3)"]},{"cell_type":"code","execution_count":null,"id":"8fa600f3","metadata":{"id":"8fa600f3","outputId":"ff16d4c6-9175-45b1-cbff-43c5fa516656"},"outputs":[{"data":{"text/plain":["23"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["len(sigma_sequence)"]},{"cell_type":"code","execution_count":null,"id":"23647ac0","metadata":{"scrolled":true,"id":"23647ac0","outputId":"0bd0f16e-1ed5-4341-aa70-7812833afa1e"},"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(22, 480, 480), dtype=float32, numpy=\n","array([[[3.0978464e-07, 2.7119140e-07, 9.9703016e-08, ...,\n","         4.2687549e-08, 2.5484357e-07, 3.3015252e-07],\n","        [3.0978464e-07, 2.7119140e-07, 9.9703016e-08, ...,\n","         1.3677284e-08, 1.2293613e-07, 2.5500006e-07],\n","        [3.0978464e-07, 2.7119140e-07, 9.9703016e-08, ...,\n","         7.8977491e-09, 1.3684598e-08, 4.2737952e-08],\n","        ...,\n","        [5.8261314e-05, 1.0739290e-04, 1.0370372e-04, ...,\n","         7.6804346e-05, 3.9270653e-05, 9.7602395e-05],\n","        [3.8807699e-05, 6.5753047e-05, 6.3208478e-05, ...,\n","         3.3165968e-05, 2.0603688e-05, 9.7295000e-05],\n","        [3.8805956e-05, 1.0643967e-04, 8.4387953e-05, ...,\n","         1.8008228e-05, 3.3787801e-06, 1.2425105e-05]],\n","\n","       [[2.4247140e-07, 1.3556784e-07, 2.0695704e-07, ...,\n","         1.6173999e-08, 1.6429491e-08, 8.5801616e-08],\n","        [2.4247140e-07, 1.3556784e-07, 2.0695704e-07, ...,\n","         8.9912646e-09, 3.3783181e-09, 1.6431613e-08],\n","        [2.7442306e-07, 1.4965379e-07, 2.1540041e-07, ...,\n","         1.1329121e-08, 1.0536041e-08, 1.8283799e-08],\n","        ...,\n","        [6.3610445e-05, 6.5167704e-05, 3.5606616e-05, ...,\n","         1.7406806e-05, 3.8702856e-06, 1.5388941e-06],\n","        [7.2195340e-05, 7.7340228e-05, 3.3082033e-05, ...,\n","         3.4773839e-06, 2.6334892e-06, 9.4890129e-06],\n","        [5.0629402e-05, 5.4646884e-05, 1.5009699e-05, ...,\n","         3.3613567e-06, 2.0617929e-06, 1.3518574e-05]],\n","\n","       [[7.0915316e-06, 5.8352621e-06, 3.3773101e-06, ...,\n","         1.4319947e-06, 1.6509065e-06, 1.8324127e-06],\n","        [8.0863456e-06, 6.7382266e-06, 4.0626724e-06, ...,\n","         1.5850088e-06, 1.9883585e-06, 2.2546733e-06],\n","        [9.6463618e-06, 8.1711050e-06, 5.2110486e-06, ...,\n","         2.1886776e-06, 2.7729257e-06, 3.1131174e-06],\n","        ...,\n","        [2.1623290e-04, 1.3502403e-04, 6.5677683e-05, ...,\n","         1.6757489e-04, 1.1307673e-04, 9.3204901e-05],\n","        [5.8260537e-04, 3.5551653e-04, 1.3512316e-04, ...,\n","         1.3834808e-04, 1.0006444e-04, 8.2771141e-05],\n","        [8.1877335e-04, 4.9141899e-04, 1.7288048e-04, ...,\n","         1.3694139e-04, 1.1470126e-04, 8.9470530e-05]],\n","\n","       ...,\n","\n","       [[8.2761730e-04, 8.2787871e-04, 8.2772784e-04, ...,\n","         1.1393074e-03, 1.1392453e-03, 1.1391640e-03],\n","        [8.2733482e-04, 8.2724541e-04, 8.2739751e-04, ...,\n","         1.1387082e-03, 1.1391193e-03, 1.1389740e-03],\n","        [8.2644820e-04, 8.2635629e-04, 8.2647614e-04, ...,\n","         1.1376174e-03, 1.1375801e-03, 1.1377564e-03],\n","        ...,\n","        [9.6173957e-04, 9.6163776e-04, 9.6152973e-04, ...,\n","         7.0598535e-04, 7.0600462e-04, 7.0590962e-04],\n","        [9.6156634e-04, 9.6165884e-04, 9.6148002e-04, ...,\n","         7.0565566e-04, 7.0574507e-04, 7.0579787e-04],\n","        [9.6118945e-04, 9.6134905e-04, 9.6095604e-04, ...,\n","         7.0586550e-04, 7.0605986e-04, 7.0591457e-04]],\n","\n","       [[2.9207133e-03, 2.9202451e-03, 2.9202141e-03, ...,\n","         4.2248829e-03, 4.2248727e-03, 4.2249784e-03],\n","        [2.9211130e-03, 2.9209193e-03, 2.9202998e-03, ...,\n","         4.2257435e-03, 4.2248680e-03, 4.2249113e-03],\n","        [2.9215093e-03, 2.9212262e-03, 2.9212385e-03, ...,\n","         4.2254217e-03, 4.2255805e-03, 4.2256266e-03],\n","        ...,\n","        [3.4804430e-03, 3.4802456e-03, 3.4801401e-03, ...,\n","         2.7570527e-03, 2.7567819e-03, 2.7571160e-03],\n","        [3.4813285e-03, 3.4812663e-03, 3.4809608e-03, ...,\n","         2.7574797e-03, 2.7572575e-03, 2.7576101e-03],\n","        [3.4819331e-03, 3.4815334e-03, 3.4818761e-03, ...,\n","         2.7577740e-03, 2.7571495e-03, 2.7574499e-03]],\n","\n","       [[1.6279022e-04, 1.6292930e-04, 1.6300257e-04, ...,\n","         2.3697440e-04, 2.3708120e-04, 2.3703526e-04],\n","        [1.6304106e-04, 1.6307209e-04, 1.6306713e-04, ...,\n","         2.3696820e-04, 2.3700669e-04, 2.3706257e-04],\n","        [1.6359364e-04, 1.6346325e-04, 1.6330679e-04, ...,\n","         2.3706134e-04, 2.3698062e-04, 2.3687507e-04],\n","        ...,\n","        [2.0923465e-04, 2.0928681e-04, 2.0929675e-04, ...,\n","         1.6521041e-04, 1.6526009e-04, 1.6523649e-04],\n","        [2.0929675e-04, 2.0933151e-04, 2.0939980e-04, ...,\n","         1.6526257e-04, 1.6527002e-04, 1.6525760e-04],\n","        [2.0957738e-04, 2.0949666e-04, 2.0945196e-04, ...,\n","         1.6504899e-04, 1.6510363e-04, 1.6512473e-04]]], dtype=float32)>"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["wd_sigma_list"]},{"cell_type":"code","execution_count":null,"id":"2d8b0523-f8ca-4e13-93a5-e788753f26f8","metadata":{"id":"2d8b0523-f8ca-4e13-93a5-e788753f26f8"},"outputs":[],"source":["sigma_map = np.zeros([height, width])\n","\n","for x in range(height):\n","    for y in range(width):\n","        # print(f\"Processing position: ({x}, {y})\")\n","        pixel_wd_values = wd_sigma_list[:,x,y].numpy().tolist()\n","        wd_values_under_5 = wd_sigma_list[:4,x,y].numpy().tolist()\n","\n","        # print(\"Pixel Value:\", pixel_wd_values)\n","        max_wd_under_5 = max(wd_values_under_5) if wd_values_under_5 else 0\n","        # print(\"Max value under sigma 5:\", max_wd_under_5)\n","\n","        # Check if max_wd_under_5 is among the top 5 values in the full list\n","        top_values = sorted(pixel_wd_values, reverse=True)[:5]\n","        is_top_five = max_wd_under_5 in top_values\n","\n","        # Check if max_wd_under_5 is the overall maximum\n","        overall_max = max(pixel_wd_values)\n","        is_overall_max = max_wd_under_5 == overall_max\n","\n","        differences = np.diff(pixel_wd_values)\n","        # print(\"differences:\", differences)\n","\n","        # Find the first index where sigma is greater than 10\n","        if is_top_five:\n","            start_index = pixel_wd_values.index(max_wd_under_5) + 1\n","        else:\n","            start_index = next(\n","                (index-1 for index, sigma in enumerate(sigma_sequence) if sigma >= 15),\n","                len(sigma_sequence) - 1\n","            )\n","\n","        trend_changes = []\n","\n","        i = 0\n","        while i < len(differences):\n","            if differences[i] > 0:\n","                start = i\n","                while i < len(differences) and differences[i] > 0:\n","                    i += 1\n","                trend_changes.append((start, i-1))\n","            i += 1\n","        # print(\"Trend_change:\", trend_changes)\n","\n","        if is_overall_max:\n","            found_significant = False\n","            index = pixel_wd_values.index(overall_max) + 1\n","            for i in range(index, len(sigma_sequence) - 1):\n","                if pixel_wd_values[i] * 10 > max_wd_under_5:\n","                    sigma_map[x, y] = sigma_sequence[i]\n","                    found_significant = True\n","                    # print(f\"Optimal Sigma value at ({x}, {y}): {sigma_map[x, y]}\")\n","                    break\n","            if not found_significant:\n","                sigma_map[x, y] = 0\n","                # print(f\"No significant sigma found at ({x}, {y}), set to 0\")\n","            continue\n","\n","        for start, end in trend_changes:\n","            if start >= start_index or (start <= start_index <= end):\n","                if pixel_wd_values[end] / max_wd_under_5 > threshold:\n","                    sigma_map[x, y] = sigma_sequence[end + 1]\n","                    # print(f\"Optimal Sigma value at ({x}, {y}): {sigma_map[x, y]}\")\n","                    break"]},{"cell_type":"code","execution_count":null,"id":"eb4535df","metadata":{"id":"eb4535df","outputId":"4e9a22e2-f105-4996-bf11-b96467d558f0"},"outputs":[{"data":{"text/plain":["(480, 480)"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["sigma_map.shape"]},{"cell_type":"code","execution_count":null,"id":"541479c4-e40b-4d94-bdef-cd6006e25f5a","metadata":{"id":"541479c4-e40b-4d94-bdef-cd6006e25f5a","outputId":"75f7dcac-005c-48ed-bae0-0d4f6da17f04"},"outputs":[{"name":"stdout","output_type":"stream","text":["Image saved as sheepdog_sigma_map_heatmap.png\n"]}],"source":["np.save(filename+'_sigma_map_v6.npy', sigma_map)\n","sigma_map_normalized = (sigma_map * 255 / np.max(sigma_map)).astype(np.uint8)\n","im = Image.fromarray(sigma_map_normalized, mode='L')\n","fname = filename + '_sigma_map_heatmap.png'\n","im.save(fname)\n","print('Image saved as', fname)"]},{"cell_type":"code","execution_count":null,"id":"fb35cf99-8195-4320-b24f-f4b0030e06eb","metadata":{"id":"fb35cf99-8195-4320-b24f-f4b0030e06eb"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}